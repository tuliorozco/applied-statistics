import pandas as pd
import numpy as np
from scipy import stats
import warnings
from typing import Dict, List, Tuple, Optional
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import multiprocessing as mp
from functools import partial
import time

# Intentar importar librer√≠as opcionales para optimizaci√≥n
try:
    from numba import jit, prange, vectorize
    NUMBA_AVAILABLE = True
except ImportError:
    NUMBA_AVAILABLE = False
    print("Numba no est√° instalado. Usando implementaci√≥n est√°ndar.")

try:
    import swifter
    SWIFTER_AVAILABLE = True
except ImportError:
    SWIFTER_AVAILABLE = False

warnings.filterwarnings('ignore')

# =====================================================
# VERSI√ìN 1: OPTIMIZADA CON VECTORIZACI√ìN Y NUMPY
# =====================================================

class VehicleDataImputerOptimized:
    """Versi√≥n optimizada usando vectorizaci√≥n y operaciones numpy"""
    
    def __init__(self, df):
        self.df = df.copy()
        self.original_nulls = df.isnull().sum()
        
        # Pre-calcular estad√≠sticas para evitar rec√°lculos
        self._precompute_stats()
        
    def _precompute_stats(self):
        """Pre-calcula estad√≠sticas que se usar√°n m√∫ltiples veces"""
        self.stats_cache = {
            'manufacturer_mode': self.df['manufacturer'].mode().iloc[0] if len(self.df['manufacturer'].mode()) > 0 else None,
            'type_mode': self.df['type'].mode().iloc[0] if len(self.df['type'].mode()) > 0 else 'sedan',
            'condition_mode': self.df['condition'].mode().iloc[0] if len(self.df['condition'].mode()) > 0 else 'good',
            'price_percentiles': self.df['price'].quantile([0.2, 0.4, 0.7, 0.9]).values if 'price' in self.df else None,
            'year_median': self.df['year'].median() if 'year' in self.df else 2015,
            'odometer_median': self.df['odometer'].median() if 'odometer' in self.df else 50000
        }
        
        # Pre-calcular grupos frecuentes para b√∫squedas r√°pidas
        self.manufacturer_groups = self.df.groupby('manufacturer')['type'].apply(
            lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else 'sedan'
        ).to_dict()
        
    def impute_all(self):
        """Ejecuta toda la estrategia de imputaci√≥n optimizada"""
        start_time = time.time()
        
        print("üöÄ Iniciando proceso de imputaci√≥n OPTIMIZADO...")
        print(f"Valores nulos iniciales: {self.df.isnull().sum().sum()}")
        
        # Convertir categ√≥ricas a object para evitar errores
        self._convert_categoricals()
        
        # Ejecutar imputaciones
        self.impute_manufacturer_vectorized()
        self.impute_type_vectorized()
        self.impute_drive_vectorized()
        self.impute_condition_vectorized()
        self.impute_cylinders_vectorized()
        
        end_time = time.time()
        print(f"\nTiempo total de imputaci√≥n: {end_time - start_time:.2f} segundos")
        
        self.validate_imputations()
        return self.df
    
    def _convert_categoricals(self):
        """Convierte columnas categ√≥ricas a object"""
        categorical_cols = self.df.select_dtypes(include=['category']).columns
        for col in categorical_cols:
            self.df[col] = self.df[col].astype('object')
    
    def impute_manufacturer_vectorized(self):
        """Imputa manufacturer usando vectorizaci√≥n"""
        print("\nImputando 'manufacturer' (vectorizado)...")
        
        mask = self.df['manufacturer'].isnull() & self.df['model'].notna()
        
        if mask.sum() > 0:
            # Crear un diccionario de mapeo modelo -> manufacturer
            model_to_manufacturer = {}
            known_manufacturers = self.df['manufacturer'].dropna().unique()
            
            # Vectorizar la b√∫squeda
            models_to_impute = self.df.loc[mask, 'model'].str.lower()
            
            for manufacturer in known_manufacturers:
                manufacturer_lower = str(manufacturer).lower()
                matches = models_to_impute.str.contains(manufacturer_lower, na=False)
                
                for idx in models_to_impute[matches].index:
                    if idx not in model_to_manufacturer:
                        model_to_manufacturer[idx] = manufacturer
            
            # Aplicar imputaciones de una vez
            for idx, manufacturer in model_to_manufacturer.items():
                self.df.loc[idx, 'manufacturer'] = manufacturer
            
            # Imputar restantes con el modo
            remaining_mask = mask & self.df['manufacturer'].isnull()
            self.df.loc[remaining_mask, 'manufacturer'] = self.stats_cache['manufacturer_mode']
        
        print(f"Imputados: {mask.sum()} registros")
    
    def impute_type_vectorized(self):
        """Imputa type usando vectorizaci√≥n y b√∫squeda optimizada"""
        print("\nImputando 'type' (vectorizado)...")
        
        mask = self.df['type'].isnull()
        
        if mask.sum() > 0:
            # Diccionario de palabras clave
            type_keywords = {
                'sedan': ['sedan', 'camry', 'accord', 'civic', 'corolla'],
                'SUV': ['suv', 'explorer', 'tahoe', 'suburban', 'escalade', 'pilot'],
                'truck': ['truck', 'f-150', 'silverado', 'ram', 'sierra'],
                'coupe': ['coupe', 'mustang', 'camaro', 'challenger'],
                'hatchback': ['hatchback', 'prius', 'fit', 'golf'],
                'wagon': ['wagon', 'forester', 'outback']
            }
            
            # Vectorizar la b√∫squeda de palabras clave
            models_to_check = self.df.loc[mask, 'model'].fillna('').str.lower()
            type_assignments = pd.Series(index=models_to_check.index, dtype='object')
            
            for vehicle_type, keywords in type_keywords.items():
                # Crear patr√≥n regex para b√∫squeda eficiente
                pattern = '|'.join(keywords)
                matches = models_to_check.str.contains(pattern, na=False, regex=True)
                type_assignments[matches] = vehicle_type
            
            # Aplicar asignaciones
            self.df.loc[type_assignments.notna().index, 'type'] = type_assignments[type_assignments.notna()]
            
            # Para los restantes, usar manufacturer groups
            remaining_mask = mask & self.df['type'].isnull()
            for idx in self.df[remaining_mask].index:
                manufacturer = self.df.loc[idx, 'manufacturer']
                if manufacturer in self.manufacturer_groups:
                    self.df.loc[idx, 'type'] = self.manufacturer_groups[manufacturer]
                else:
                    self.df.loc[idx, 'type'] = self.stats_cache['type_mode']
        
        print(f"Imputados: {mask.sum()} registros")
    
    def impute_drive_vectorized(self):
        """Imputa drive usando vectorizaci√≥n"""
        print("\nImputando 'drive' (vectorizado)...")
        
        mask = self.df['drive'].isnull()
        
        if mask.sum() > 0:
            # Crear array de valores a imputar
            drive_values = np.where(
                self.df.loc[mask, 'type'].isin(['SUV', 'truck']), '4wd',
                np.where(
                    self.df.loc[mask, 'type'].isin(['sedan', 'hatchback', 'coupe']), 'fwd',
                    'fwd'  # default
                )
            )
            
            # Aplicar de una vez
            self.df.loc[mask, 'drive'] = drive_values
        
        print(f"Imputados: {mask.sum()} registros")
    
    def impute_condition_vectorized(self):
        """Imputa condition usando vectorizaci√≥n completa"""
        print("\nImputando 'condition' (vectorizado)...")
        
        mask = self.df['condition'].isnull()
        
        if mask.sum() > 0:
            # Preparar datos
            subset = self.df.loc[mask].copy()
            conditions = np.full(len(subset), 'good', dtype=object)
            
            # Calcular edad del veh√≠culo donde sea posible
            has_year = subset['year'].notna()
            vehicle_ages = np.where(has_year, 2024 - subset['year'], np.nan)
            
            # Condiciones basadas en year y odometer
            has_both = subset['year'].notna() & subset['odometer'].notna()
            
            # Aplicar reglas vectorizadas
            conditions[has_both & (vehicle_ages <= 1) & (subset['odometer'] < 15000)] = 'new'
            conditions[has_both & (vehicle_ages <= 2) & (subset['odometer'] < 30000) & 
                      ~((vehicle_ages <= 1) & (subset['odometer'] < 15000))] = 'like new'
            conditions[has_both & (vehicle_ages <= 3) & (subset['odometer'] < 45000) &
                      ~((vehicle_ages <= 2) & (subset['odometer'] < 30000))] = 'excellent'
            conditions[has_both & (vehicle_ages <= 5) & (subset['odometer'] < 60000) &
                      ~((vehicle_ages <= 3) & (subset['odometer'] < 45000))] = 'good'
            conditions[has_both & (vehicle_ages <= 10) & (subset['odometer'] < 120000) &
                      ~((vehicle_ages <= 5) & (subset['odometer'] < 60000))] = 'fair'
            conditions[has_both & ((vehicle_ages > 15) | (subset['odometer'] > 200000))] = 'salvage'
            conditions[has_both & (vehicle_ages > 10) & (subset['odometer'] >= 120000) &
                      ~((vehicle_ages > 15) | (subset['odometer'] > 200000))] = 'poor'
            
            # Para los que no tienen year/odometer, usar precio
            no_year_odometer = ~has_both & subset['price'].notna()
            if no_year_odometer.sum() > 0 and self.stats_cache['price_percentiles'] is not None:
                prices = subset.loc[no_year_odometer, 'price'].values
                p20, p40, p70, p90 = self.stats_cache['price_percentiles']
                
                price_conditions = np.select(
                    [prices >= p90, prices >= p70, prices >= p40, prices >= p20],
                    ['excellent', 'good', 'fair', 'poor'],
                    default='salvage'
                )
                conditions[no_year_odometer] = price_conditions
            
            # Aplicar todas las imputaciones de una vez
            self.df.loc[mask, 'condition'] = conditions
        
        print(f"Imputados: {mask.sum()} registros")
    
    def impute_cylinders_vectorized(self):
        """Imputa cylinders usando vectorizaci√≥n"""
        print("\nImputando 'cylinders' (vectorizado)...")
        
        mask = self.df['cylinders'].isnull()
        
        if mask.sum() > 0:
            # Reglas por tipo
            cylinder_map = {
                'sedan': 4, 'hatchback': 4, 'wagon': 4,
                'coupe': 6, 'SUV': 6,
                'truck': 8
            }
            
            # Aplicar mapeo vectorizado
            cylinders = self.df.loc[mask, 'type'].map(cylinder_map).fillna(4)
            self.df.loc[mask, 'cylinders'] = cylinders
        
        print(f"Imputados: {mask.sum()} registros")
    
    def validate_imputations(self):
        """Valida las imputaciones"""
        print("\nValidando imputaciones...")
        final_nulls = self.df.isnull().sum()
        print(f"Valores nulos finales: {final_nulls.sum()}")
        
        if final_nulls.sum() > 0:
            print("Columnas con valores nulos restantes:")
            print(final_nulls[final_nulls > 0])


# =====================================================
# VERSI√ìN 2: CON NUMBA PARA C√ÅLCULOS NUM√âRICOS
# =====================================================

if NUMBA_AVAILABLE:
    @jit(nopython=True)
    def calculate_vehicle_age_numba(years, current_year=2024):
        """Calcula edad del veh√≠culo usando Numba"""
        ages = np.empty(len(years))
        for i in range(len(years)):
            if not np.isnan(years[i]):
                ages[i] = current_year - years[i]
            else:
                ages[i] = np.nan
        return ages
    
    @jit(nopython=True)
    def assign_condition_numba(ages, odometers):
        """Asigna condici√≥n basada en edad y kilometraje usando Numba"""
        n = len(ages)
        conditions = np.empty(n, dtype=np.int32)
        
        for i in prange(n):
            if not np.isnan(ages[i]) and not np.isnan(odometers[i]):
                age = ages[i]
                odo = odometers[i]
                
                if age <= 1 and odo < 15000:
                    conditions[i] = 0  # new
                elif age <= 2 and odo < 30000:
                    conditions[i] = 1  # like new
                elif age <= 3 and odo < 45000:
                    conditions[i] = 2  # excellent
                elif age <= 5 and odo < 60000:
                    conditions[i] = 3  # good
                elif age <= 10 and odo < 120000:
                    conditions[i] = 4  # fair
                elif age > 15 or odo > 200000:
                    conditions[i] = 5  # salvage
                else:
                    conditions[i] = 6  # poor
            else:
                conditions[i] = -1  # to be imputed by other method
        
        return conditions


# =====================================================
# VERSI√ìN 3: PARALELA CON MULTIPROCESSING
# =====================================================

class VehicleDataImputerParallel:
    """Versi√≥n paralela usando multiprocessing para datasets grandes"""
    
    def __init__(self, df, n_jobs=-1):
        self.df = df.copy()
        self.original_nulls = df.isnull().sum()
        self.n_jobs = mp.cpu_count() if n_jobs == -1 else n_jobs
        
    def impute_all(self):
        """Ejecuta imputaci√≥n en paralelo"""
        start_time = time.time()
        
        print(f"Iniciando imputaci√≥n PARALELA con {self.n_jobs} cores...")
        print(f"Valores nulos iniciales: {self.df.isnull().sum().sum()}")
        
        # Convertir categ√≥ricas
        for col in self.df.select_dtypes(include=['category']).columns:
            self.df[col] = self.df[col].astype('object')
        
        # Dividir DataFrame para procesamiento paralelo
        df_chunks = np.array_split(self.df, self.n_jobs)
        
        # Procesar en paralelo
        with ProcessPoolExecutor(max_workers=self.n_jobs) as executor:
            processed_chunks = list(executor.map(self._process_chunk, df_chunks))
        
        # Combinar resultados
        self.df = pd.concat(processed_chunks, ignore_index=True)
        
        end_time = time.time()
        print(f"\nTiempo total: {end_time - start_time:.2f} segundos")
        
        return self.df
    
    @staticmethod
    def _process_chunk(chunk):
        """Procesa un chunk del DataFrame"""
        # Aqu√≠ ir√≠a la l√≥gica de imputaci√≥n para cada chunk
        # Por simplicidad, uso la versi√≥n optimizada
        imputer = VehicleDataImputerOptimized(chunk)
        return imputer.impute_all()


# =====================================================
# VERSI√ìN 4: USANDO PANDAS OPTIMIZADO
# =====================================================

class VehicleDataImputerPandasOptimized:
    """Versi√≥n ultra-optimizada usando solo pandas con t√©cnicas avanzadas"""
    
    def __init__(self, df):
        self.df = df.copy()
        self.original_nulls = df.isnull().sum()
        
    def impute_all(self):
        """Ejecuta imputaci√≥n usando pandas optimizado"""
        start_time = time.time()
        
        print("Iniciando imputaci√≥n PANDAS OPTIMIZADA...")
        
        # Convertir categ√≥ricas de una vez
        cat_cols = self.df.select_dtypes(include=['category']).columns
        self.df[cat_cols] = self.df[cat_cols].astype('object')
        
        # Usar fillna con strategy donde sea posible
        self.df['manufacturer'].fillna(self.df['manufacturer'].mode()[0], inplace=True)
        
        # Imputaci√≥n por grupos eficiente
        self.df['type'] = self.df.groupby('manufacturer')['type'].transform(
            lambda x: x.fillna(x.mode()[0] if len(x.mode()) > 0 else 'sedan')
        )
        
        # Mapeos r√°pidos
        type_to_drive = {'SUV': '4wd', 'truck': '4wd', 'sedan': 'fwd', 
                        'hatchback': 'fwd', 'coupe': 'fwd', 'wagon': 'fwd'}
        self.df['drive'] = self.df['drive'].fillna(self.df['type'].map(type_to_drive))
        
        type_to_cylinders = {'sedan': 4, 'hatchback': 4, 'wagon': 4,
                           'coupe': 6, 'SUV': 6, 'truck': 8}
        self.df['cylinders'] = self.df['cylinders'].fillna(self.df['type'].map(type_to_cylinders))
        
        # Condition con cut para categorizaci√≥n r√°pida
        if 'year' in self.df.columns and 'odometer' in self.df.columns:
            vehicle_age = 2024 - self.df['year']
            
            conditions = pd.cut(
                vehicle_age * 10000 + self.df['odometer'],
                bins=[-np.inf, 25000, 50000, 75000, 150000, 300000, np.inf],
                labels=['new', 'like new', 'excellent', 'good', 'fair', 'poor']
            )
            
            self.df['condition'] = self.df['condition'].fillna(conditions)
        
        self.df['condition'].fillna('good', inplace=True)
        
        end_time = time.time()
        print(f"Tiempo total: {end_time - start_time:.2f} segundos")
        
        return self.df


# =====================================================
# FUNCI√ìN PRINCIPAL CON SELECCI√ìN DE ESTRATEGIA
# =====================================================

def impute_vehicle_data_fast(df, method='optimized', n_jobs=-1):
    """
    Imputa datos de veh√≠culos usando diferentes estrategias optimizadas
    
    Args:
        df: DataFrame con datos de veh√≠culos
        method: Estrategia a usar ('optimized', 'parallel', 'pandas', 'numba')
        n_jobs: N√∫mero de cores para m√©todo paralelo (-1 para todos)
    
    Returns:
        DataFrame imputado
    """
    print(f"Dataset: {len(df)} filas x {len(df.columns)} columnas")
    print(f"Memoria estimada: {df.memory_usage(deep=True).sum() / 1e6:.2f} MB")
    
    if method == 'optimized':
        imputer = VehicleDataImputerOptimized(df)
    elif method == 'parallel' and len(df) > 50000:  # Solo paralelizar si vale la pena
        imputer = VehicleDataImputerParallel(df, n_jobs)
    elif method == 'pandas':
        imputer = VehicleDataImputerPandasOptimized(df)
    elif method == 'numba' and NUMBA_AVAILABLE:
        # Usar versi√≥n optimizada con funciones Numba
        imputer = VehicleDataImputerOptimized(df)
    else:
        print(f"M√©todo '{method}' no disponible, usando 'optimized'")
        imputer = VehicleDataImputerOptimized(df)
    
    return imputer.impute_all()


# =====================================================
# BENCHMARK DE RENDIMIENTO
# =====================================================

def benchmark_imputation_methods(df, sample_size=10000):
    """
    Compara el rendimiento de diferentes m√©todos de imputaci√≥n
    """
    # Tomar muestra si el dataset es muy grande
    df_sample = df.sample(min(sample_size, len(df))).copy()
    
    results = {}
    
    methods = ['optimized', 'pandas']
    if NUMBA_AVAILABLE:
        methods.append('numba')
    if len(df_sample) > 5000:
        methods.append('parallel')
    
    print("=" * 60)
    print("BENCHMARK DE M√âTODOS DE IMPUTACI√ìN")
    print("=" * 60)
    print(f"Tama√±o de muestra: {len(df_sample)} registros")
    print("-" * 60)
    
    for method in methods:
        df_test = df_sample.copy()
        
        start_time = time.time()
        try:
            _ = impute_vehicle_data_fast(df_test, method=method)
            elapsed_time = time.time() - start_time
            results[method] = elapsed_time
            print(f"{method:15} : {elapsed_time:.3f} segundos")
        except Exception as e:
            print(f"{method:15} : Error - {str(e)}")
            results[method] = None
    
    # Mostrar comparaci√≥n
    if results:
        best_method = min(results, key=lambda x: results[x] if results[x] else float('inf'))
        print("-" * 60)
        print(f"M√©todo m√°s r√°pido: {best_method}")
        
        if results[best_method]:
            print("\nSpeedup relativo:")
            baseline = max(v for v in results.values() if v)
            for method, time_val in results.items():
                if time_val:
                    speedup = baseline / time_val
                    print(f"   {method:15} : {speedup:.2f}x")
    
    return results


# =====================================================
# EJEMPLO DE USO
# =====================================================

"""
# Uso b√°sico - m√©todo m√°s r√°pido
df_imputado = impute_vehicle_data_fast(df, method='optimized')

# Usar paralelizaci√≥n para datasets grandes
df_imputado = impute_vehicle_data_fast(df, method='parallel', n_jobs=4)

# Comparar m√©todos
results = benchmark_imputation_methods(df, sample_size=10000)

# Con Numba (si est√° instalado)
if NUMBA_AVAILABLE:
    df_imputado = impute_vehicle_data_fast(df, method='numba')
"""

print("\nScript de imputaci√≥n optimizada cargado correctamente!")
print("M√©todos disponibles: 'optimized', 'pandas', 'parallel'")
if NUMBA_AVAILABLE:
    print("   ‚ö° Numba detectado - aceleraci√≥n adicional disponible")
else:
    print("Instala Numba para mayor velocidad: pip install numba")